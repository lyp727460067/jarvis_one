%YAML:1.0

#common parameters
#support: 1 imu 1 cam; 1 imu 2 cam: 2 cam; 
imu: 1         
num_of_cam: 1  

imu_topic: "/imu0"
image0_topic: "/usb_cam_1/image_raw/compressed"
image1_topic: "/usb_cam_2/image_raw/compressed"
output_path: "/home/lyp/project/catkin_ws/log"

# data_folder: "/home/lyp/project/dataset/slam_test/20230908/2023-09-08-11-45-59.bag"

# data_folder: "/home/lyp/project/dataset/relocation_test/2023-07-13-09-59-39.bag"
# data_folder: "/home/lyp/project/dataset/slam_test/20230810/203/2023-08-10-09-54-04.bag"
# data_folder: "/home/lyp/project/dataset/slam_test/20230915/000/2023-09-15-11-53-49.bag"
# data_folder: "/home/lyp/project/dataset/slam_test/20231017/000/2023-10-18-10-18-17.bag"
data_folder: "/home/lyp/Downloads/images2/data.bag"
cam0_calib: "cam0_pinhole.yaml"
cam1_calib: "cam1_pinhole.yaml"
image_width: 640
image_height: 480
# imu_cam_time_offset: 0.028 #1123
imu_cam_time_offset: -6.44878 #for 1209
cam0_cam1_time_offset_thresh_hold: 0.005
image_sample : 1
offline_play_bag_duration : 0.0001  

map_builder_option: mapping_builder.yaml

# Extrinsic parameter between IMU and Camera.
estimate_extrinsic: 1   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
                        # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.

body_T_cam0: !!opencv-matrix
   rows: 4
   cols: 4
   dt: d
   data: [0.713218, 0.700928, -0.0044013, -0.0562531, 
          0.700896, -0.713229, -0.00705146, -0.021057, 
          -0.00808171, 0.00194438, -0.999965, -0.00238278, 
          0, 0, 0, 1]

body_T_cam1: !!opencv-matrix
   rows: 4
   cols: 4
   dt: d
   data: [0.999871164299, -0.004243074388, 0.015480669323, 0.032420989989, 
            -0.004206777674, -0.999988327665, -0.002376458658, -0.006701934209, 
            0.015490572118, 0.002311028751, -0.999877343138, -0.005119084167, 
            0.000000000000, 0.000000000000, 0.000000000000, 1.000000000000]

#    data: [  0.999939668999831, -0.003480639301653176, -0.003480639301653176, 0.14099785959872843,
#             0.0033248743654744244, 0.999882997189949, -0.014931079696228667, -0.0008278517573185127,
#             0.010469172410421638, 0.014895538946043818, 0.9998342459370676, -0.0009040565758959566,
#             0, 0, 0, 1]

#Multiple thread support
multiple_thread: 0

#feature traker paprameters
max_cnt: 100            # max feature number in feature tracking
min_dist: 30            # min distance between two features 
freq: 10                # frequence (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequence will be same as raw image 
F_threshold: 1.0        # ransac threshold (pixel)
show_track: 1           # publish tracking image as topic
flow_back: 1           # perform forward and backward optical flow to improve feature tracking accuracy

#optimization parameters
max_solver_time: 0.05  # max solver itration time (ms), to guarantee real time
max_num_iterations: 8   # max solver itrations, to guarantee real time
keyframe_parallax: 20.0 # keyframe selection threshold (pixel)


#imu parameters       The more accurate parameters you provide, the better performance
acc_n: 0.1          # accelerometer measurement noise standard deviation. 
gyr_n: 0.01         # gyroscope measurement noise standard deviation.     
acc_w: 0.001        # accelerometer bias random work noise standard deviation.  
gyr_w: 0.0001       # gyroscope bias random work noise standard deviation.     
g_norm: 9.81007     # gravity magnitude


#unsynchronization parameters
estimate_td: 1                      # online estimate time offset between camera and imu
td: 0                                 # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)

#optimization parameters
max_num_iterations: 8   # max solver itrations, to guarantee real time
